#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
OKê¸ˆìœµê·¸ë£¹ ì§ë¬´ê¸°ìˆ ì„œ PDF ì™„ì „ íŒŒì‹± - 37ê°œ ì „ì²´ ì§ë¬´
"""

import os
import sys
import io
import json
import re
import logging
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import pandas as pd
from tqdm import tqdm
import fitz  # PyMuPDF
import openpyxl
from openpyxl.styles import Font, PatternFill, Alignment

# í•œê¸€ ì¶œë ¥ ì„¤ì •
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# ë¡œê¹… ì„¤ì •
def setup_logging(output_dir: str):
    """ë¡œê¹… ì„¤ì •"""
    log_dir = os.path.join(output_dir, 'logs')
    os.makedirs(log_dir, exist_ok=True)
    
    log_file = os.path.join(log_dir, f'migration_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    return logging.getLogger(__name__)


class CompleteJobProfileParser:
    """OKê¸ˆìœµê·¸ë£¹ ì „ì²´ ì§ë¬´ê¸°ìˆ ì„œ íŒŒì„œ"""
    
    def __init__(self, pdf_path: str, output_dir: str):
        self.pdf_path = pdf_path
        self.output_dir = output_dir
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # ì „ì²´ ì§ë¬´ ëª©ë¡ (ì²« í˜ì´ì§€ ê¸°ì¤€)
        self.all_jobs = {
            'Non-PL': {
                'ITê¸°íš': ['ì‹œìŠ¤í…œê¸°íš'],
                'ITê°œë°œ': ['ì‹œìŠ¤í…œê°œë°œ'],
                'ITìš´ì˜': ['ì‹œìŠ¤í…œê´€ë¦¬', 'ì„œë¹„ìŠ¤ìš´ì˜'],
                'ê²½ì˜ê´€ë¦¬': ['ê°ì‚¬', 'HRM', 'HRD', 'ê²½ì˜ì§€ì›', 'ë¹„ì„œ', 'PR', 'ê²½ì˜ê¸°íš', 
                            'ë””ìì¸', 'ë¦¬ìŠ¤í¬ê´€ë¦¬', 'ë§ˆì¼€íŒ…', 'ìŠ¤í¬ì¸ ì‚¬ë¬´ê´€ë¦¬', 'ìê¸ˆ', 
                            'ì¬ë¬´íšŒê³„', 'ì •ë³´ë³´ì•ˆ', 'ì¤€ë²•ì§€ì›', 'ì´ë¬´'],
                'íˆ¬ìê¸ˆìœµ': ['IBê¸ˆìœµ'],
                'ê¸°ì—…ê¸ˆìœµ': ['ê¸°ì—…ì˜ì—…ê¸°íš', 'ê¸°ì—…ì—¬ì‹ ì‹¬ì‚¬', 'ê¸°ì—…ì—¬ì‹ ê´€ë¦¬'],
                'ê¸°ì—…ì˜ì—…': ['ì—¬ì‹ ì˜ì—…'],
                'ë¦¬í…Œì¼ê¸ˆìœµ': ['ë°ì´í„°/í†µê³„', 'í”Œë«í¼/í•€í…Œí¬', 'NPLì˜ì—…ê¸°íš', 'ë¦¬í…Œì¼ì‹¬ì‚¬ê¸°íš', 
                              'PLê¸°íš', 'ëª¨ê¸°ì§€ê¸°íš', 'ìˆ˜ì‹ ê¸°íš', 'ìˆ˜ì‹ ì˜ì—…']
            },
            'PL': {
                'ê³ ê°ì§€ì›': ['ì—¬ì‹ ê³ ê°ì§€ì›', 'ì‚¬ë¬´ì§€ì›', 'ìˆ˜ì‹ ê³ ê°ì§€ì›', 'ì±„ê¶Œê´€ë¦¬ì§€ì›']
            }
        }
        
        # ì§êµ° ì¹´í…Œê³ ë¦¬ ë§¤í•‘
        self.category_mapping = {
            'ITê¸°íš': 'IT/ë””ì§€í„¸',
            'ITê°œë°œ': 'IT/ë””ì§€í„¸', 
            'ITìš´ì˜': 'IT/ë””ì§€í„¸',
            'ê²½ì˜ê´€ë¦¬': 'ê²½ì˜ì§€ì›',
            'íˆ¬ìê¸ˆìœµ': 'ê¸ˆìœµ',
            'ê¸°ì—…ê¸ˆìœµ': 'ê¸ˆìœµ',
            'ê¸°ì—…ì˜ì—…': 'ì˜ì—…',
            'ë¦¬í…Œì¼ê¸ˆìœµ': 'ê¸ˆìœµ',
            'ê³ ê°ì§€ì›': 'ê³ ê°ì„œë¹„ìŠ¤'
        }
        
        self.parsed_jobs = []
    
    def extract_text_from_pdf(self) -> List[Tuple[int, str]]:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        self.logger.info(f"PDF íŒŒì¼ ì½ê¸° ì‹œì‘: {self.pdf_path}")
        
        try:
            doc = fitz.open(self.pdf_path)
            pages_text = []
            
            for page_num in range(len(doc)):
                page = doc[page_num]
                text = page.get_text()
                pages_text.append((page_num + 1, text))
                
            doc.close()
            self.logger.info(f"ì´ {len(pages_text)}í˜ì´ì§€ ì¶”ì¶œ ì™„ë£Œ")
            return pages_text
            
        except Exception as e:
            self.logger.error(f"PDF ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            raise
    
    def parse_job_profile_pages(self, pages_text: List[Tuple[int, str]]) -> List[Dict]:
        """Job Profile í˜ì´ì§€ íŒŒì‹±"""
        jobs = []
        
        for i in range(len(pages_text)):
            page_num, text = pages_text[i]
            
            # Job Profile í—¤ë” í˜ì´ì§€ ì°¾ê¸°
            if 'Job Profile' in text and 'ì§êµ°' in text:
                job_data = {'page_number': page_num}
                
                # ì§êµ° êµ¬ë¶„ (Non-PL / PL)
                if 'Non-PLì§êµ°' in text:
                    job_data['group'] = 'Non-PL'
                elif 'PLì§êµ°' in text:
                    job_data['group'] = 'PL'
                else:
                    continue
                
                # ì§ì¢… ì¶”ì¶œ
                # íŒ¨í„´: "ì§êµ°ê²½ì˜ê´€ë¦¬ì§ì¢…ê°ì‚¬" ë˜ëŠ” "ì§êµ°ITê¸°íšì§ì¢…ì‹œìŠ¤í…œê¸°íš"
                type_match = re.search(r'ì§êµ°([ê°€-í£/]+)ì§ì¢…([ê°€-í£/\s]+)', text)
                if type_match:
                    job_type = type_match.group(1).strip()
                    job_name_hint = type_match.group(2).strip()
                    
                    job_data['job_type'] = job_type
                    job_data['job_category'] = self.category_mapping.get(job_type, 'ê¸°íƒ€')
                    
                    self.logger.info(f"í˜ì´ì§€ {page_num}: {job_data['group']} - {job_type}")
                
                # ë‹¤ìŒ í˜ì´ì§€ì—ì„œ ì§ë¬´ ìƒì„¸ ì •ë³´ ì¶”ì¶œ
                if i + 1 < len(pages_text):
                    next_page_num, next_text = pages_text[i + 1]
                    
                    # ì§ë¬´ëª… ì¶”ì¶œ
                    job_match = re.search(r'ì§ë¬´:\s*([^\n]+)', next_text)
                    if job_match:
                        job_data['job_title'] = job_match.group(1).strip()
                        
                        # ì—­í•  ë° ì±…ì„ ì¶”ì¶œ
                        job_data['responsibilities'] = self.extract_responsibilities(next_text)
                        
                        # ê·¸ ë‹¤ìŒ í˜ì´ì§€ì—ì„œ ê¸°ìˆ /ì§€ì‹ ì¶”ì¶œ
                        if i + 2 < len(pages_text):
                            skill_page_num, skill_text = pages_text[i + 2]
                            job_data['basic_skills'] = self.extract_skills(skill_text, 'ê¸°ë³¸ê¸°ìˆ &ì§€ì‹')
                            job_data['advanced_skills'] = self.extract_skills(skill_text, 'ì‘ìš©ê¸°ìˆ &ì§€ì‹')
                        
                        jobs.append(job_data)
                        self.logger.info(f"  -> ì§ë¬´: {job_data['job_title']}")
        
        return jobs
    
    def extract_responsibilities(self, text: str) -> List[str]:
        """í•µì‹¬ì—­í• &ì±…ì„ ì¶”ì¶œ"""
        responsibilities = []
        
        # í•µì‹¬ì—­í• &ì±…ì„ ì„¹ì…˜ ì°¾ê¸°
        if 'í•µì‹¬ì—­í• &ì±…ì„' in text:
            lines = text.split('\n')
            in_section = False
            current_item = []
            
            for line in lines:
                line = line.strip()
                
                if 'í•µì‹¬ì—­í• &ì±…ì„' in line:
                    in_section = True
                    continue
                
                if in_section:
                    # ë‹¤ìŒ ì„¹ì…˜ ì‹œì‘ ì‹œ ì¢…ë£Œ
                    if any(keyword in line for keyword in ['ê¸°ë³¸ê¸°ìˆ &ì§€ì‹', 'ì‘ìš©ê¸°ìˆ &ì§€ì‹', 'ê¸°ìˆ &ì§€ì‹']):
                        break
                    
                    # ìƒˆë¡œìš´ í•­ëª© ì‹œì‘ (ì§§ì€ ì œëª©)
                    if line and len(line.split()) <= 4 and not any(c.isdigit() for c in line) and 'ì •ì˜' not in line:
                        if current_item:
                            responsibilities.append(' '.join(current_item))
                        current_item = [line + ':']
                    elif line and current_item:
                        # ì„¤ëª… ì¶”ê°€
                        current_item.append(line)
            
            # ë§ˆì§€ë§‰ í•­ëª© ì¶”ê°€
            if current_item:
                responsibilities.append(' '.join(current_item))
        
        return responsibilities
    
    def extract_skills(self, text: str, section_name: str) -> List[str]:
        """ê¸°ìˆ &ì§€ì‹ ì¶”ì¶œ"""
        skills = []
        
        if section_name in text:
            start_idx = text.find(section_name)
            # ë‹¤ìŒ ì„¹ì…˜ê¹Œì§€ ë˜ëŠ” ëê¹Œì§€
            if section_name == 'ê¸°ë³¸ê¸°ìˆ &ì§€ì‹' and 'ì‘ìš©ê¸°ìˆ &ì§€ì‹' in text:
                end_idx = text.find('ì‘ìš©ê¸°ìˆ &ì§€ì‹', start_idx)
            else:
                end_idx = len(text)
            
            section_text = text[start_idx:end_idx]
            lines = section_text.split('\n')
            
            current_skill = []
            for line in lines[1:]:  # í—¤ë” ì œì™¸
                line = line.strip()
                
                if not line or 'ì •ì˜' in line:
                    continue
                
                # ìƒˆë¡œìš´ ìŠ¤í‚¬ í•­ëª© (ì§§ì€ ì œëª©)
                if len(line.split()) <= 4 and not any(c.isdigit() for c in line):
                    if current_skill:
                        skills.append(' '.join(current_skill))
                    current_skill = [line + ':']
                elif line and current_skill:
                    current_skill.append(line)
            
            # ë§ˆì§€ë§‰ ìŠ¤í‚¬ ì¶”ê°€
            if current_skill:
                skills.append(' '.join(current_skill))
        
        return skills
    
    def verify_completeness(self, parsed_jobs: List[Dict]) -> Dict[str, List[str]]:
        """íŒŒì‹± ì™„ì „ì„± ê²€ì¦"""
        found_jobs = {}
        missing_jobs = {}
        
        # íŒŒì‹±ëœ ì§ë¬´ ì •ë¦¬
        for job in parsed_jobs:
            group = job.get('group', 'Unknown')
            job_type = job.get('job_type', 'Unknown')
            job_title = job.get('job_title', 'Unknown')
            
            if group not in found_jobs:
                found_jobs[group] = {}
            if job_type not in found_jobs[group]:
                found_jobs[group][job_type] = []
            found_jobs[group][job_type].append(job_title)
        
        # ëˆ„ë½ëœ ì§ë¬´ í™•ì¸
        for group, types in self.all_jobs.items():
            if group not in missing_jobs:
                missing_jobs[group] = {}
            
            for job_type, jobs in types.items():
                for job in jobs:
                    found = False
                    if group in found_jobs and job_type in found_jobs[group]:
                        if any(job in found_job for found_job in found_jobs[group][job_type]):
                            found = True
                    
                    if not found:
                        if job_type not in missing_jobs[group]:
                            missing_jobs[group][job_type] = []
                        missing_jobs[group][job_type].append(job)
        
        return found_jobs, missing_jobs
    
    def parse_all(self) -> List[Dict]:
        """ì „ì²´ íŒŒì‹± ì‹¤í–‰"""
        self.logger.info("OKê¸ˆìœµê·¸ë£¹ ì§ë¬´ê¸°ìˆ ì„œ ì „ì²´ íŒŒì‹± ì‹œì‘")
        
        # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
        pages_text = self.extract_text_from_pdf()
        
        # ì§ë¬´ íŒŒì‹±
        self.parsed_jobs = self.parse_job_profile_pages(pages_text)
        
        # ì™„ì „ì„± ê²€ì¦
        found_jobs, missing_jobs = self.verify_completeness(self.parsed_jobs)
        
        # ê²°ê³¼ ì¶œë ¥
        self.logger.info(f"\nì´ íŒŒì‹±ëœ ì§ë¬´: {len(self.parsed_jobs)}ê°œ")
        
        # ê·¸ë£¹ë³„ ì§‘ê³„
        for group in ['Non-PL', 'PL']:
            group_jobs = [j for j in self.parsed_jobs if j.get('group') == group]
            self.logger.info(f"{group} ì§êµ°: {len(group_jobs)}ê°œ")
        
        # ëˆ„ë½ëœ ì§ë¬´ í™•ì¸
        total_missing = 0
        for group, types in missing_jobs.items():
            for job_type, jobs in types.items():
                if jobs:
                    total_missing += len(jobs)
                    self.logger.warning(f"ëˆ„ë½: {group} > {job_type} > {jobs}")
        
        if total_missing > 0:
            self.logger.warning(f"ì´ ëˆ„ë½ëœ ì§ë¬´: {total_missing}ê°œ")
        else:
            self.logger.info("âœ… ëª¨ë“  ì§ë¬´ê°€ ì„±ê³µì ìœ¼ë¡œ íŒŒì‹±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        return self.parsed_jobs


class JobDataExporter:
    """ì§ë¬´ ë°ì´í„° ë‚´ë³´ë‚´ê¸°"""
    
    def __init__(self, output_dir: str):
        self.output_dir = output_dir
        self.logger = logging.getLogger(self.__class__.__name__)
    
    def export_to_excel(self, jobs_data: List[Dict]) -> str:
        """Excel íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        excel_dir = os.path.join(self.output_dir, 'excel')
        os.makedirs(excel_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        excel_file = os.path.join(excel_dir, f'OKê¸ˆìœµê·¸ë£¹_ì§ë¬´ê¸°ìˆ ì„œ_ì „ì²´_{timestamp}.xlsx')
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df_data = []
        for job in jobs_data:
            df_data.append({
                'êµ¬ë¶„': job.get('group', ''),
                'ì§ì¢…': job.get('job_type', ''),
                'ì§ë¬´ëª…': job.get('job_title', ''),
                'ì§êµ°': job.get('job_category', ''),
                'í˜ì´ì§€': job.get('page_number', ''),
                'í•µì‹¬ì—­í•  ë° ì±…ì„': '\n'.join(job.get('responsibilities', [])),
                'í•„ìˆ˜ì—­ëŸ‰': '\n'.join(job.get('basic_skills', [])),
                'ìš°ëŒ€ì—­ëŸ‰': '\n'.join(job.get('advanced_skills', []))
            })
        
        df = pd.DataFrame(df_data)
        
        # Excel ì €ì¥
        with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
            # ì „ì²´ ì‹œíŠ¸
            df.to_excel(writer, sheet_name='ì „ì²´ì§ë¬´(37ê°œ)', index=False)
            
            # Non-PL / PL êµ¬ë¶„ ì‹œíŠ¸
            for group in ['Non-PL', 'PL']:
                group_df = df[df['êµ¬ë¶„'] == group]
                if not group_df.empty:
                    sheet_name = f'{group}ì§êµ°({len(group_df)}ê°œ)'
                    group_df.to_excel(writer, sheet_name=sheet_name, index=False)
            
            # ì§ì¢…ë³„ ì‹œíŠ¸
            for job_type in df['ì§ì¢…'].unique():
                if pd.notna(job_type):
                    type_df = df[df['ì§ì¢…'] == job_type]
                    sheet_name = f'{job_type}({len(type_df)}ê°œ)'[:31]
                    type_df.to_excel(writer, sheet_name=sheet_name, index=False)
        
        # ìŠ¤íƒ€ì¼ ì ìš©
        wb = openpyxl.load_workbook(excel_file)
        
        for sheet_name in wb.sheetnames:
            ws = wb[sheet_name]
            
            # í—¤ë” ìŠ¤íƒ€ì¼
            header_fill = PatternFill(start_color='366092', end_color='366092', fill_type='solid')
            header_font = Font(color='FFFFFF', bold=True, size=11)
            
            for cell in ws[1]:
                cell.fill = header_fill
                cell.font = header_font
                cell.alignment = Alignment(horizontal='center', vertical='center')
            
            # ì—´ ë„ˆë¹„ ì¡°ì •
            column_widths = {
                'A': 10,   # êµ¬ë¶„
                'B': 15,   # ì§ì¢…
                'C': 25,   # ì§ë¬´ëª…
                'D': 15,   # ì§êµ°
                'E': 10,   # í˜ì´ì§€
                'F': 60,   # ì—­í• 
                'G': 50,   # í•„ìˆ˜ì—­ëŸ‰
                'H': 50    # ìš°ëŒ€ì—­ëŸ‰
            }
            
            for col, width in column_widths.items():
                if col in ws.column_dimensions:
                    ws.column_dimensions[col].width = width
            
            # í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ
            for row in ws.iter_rows(min_row=2):
                for cell in row:
                    cell.alignment = Alignment(wrap_text=True, vertical='top')
                    if cell.column in [6, 7, 8]:  # F, G, H ì—´
                        ws.row_dimensions[cell.row].height = 100
        
        wb.save(excel_file)
        self.logger.info(f"Excel ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {excel_file}")
        return excel_file
    
    def export_to_json(self, jobs_data: List[Dict]) -> str:
        """JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        json_dir = os.path.join(self.output_dir, 'json')
        os.makedirs(json_dir, exist_ok=True)
        
        json_file = os.path.join(json_dir, 'ok_job_profiles_complete.json')
        
        # êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì €ì¥
        structured_data = {
            'metadata': {
                'total_jobs': len(jobs_data),
                'non_pl_jobs': len([j for j in jobs_data if j.get('group') == 'Non-PL']),
                'pl_jobs': len([j for j in jobs_data if j.get('group') == 'PL']),
                'exported_at': datetime.now().isoformat()
            },
            'jobs': jobs_data
        }
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(structured_data, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"JSON ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {json_file}")
        return json_file
    
    def generate_summary_report(self, jobs_data: List[Dict]) -> str:
        """ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
        report_file = os.path.join(self.output_dir, 'COMPLETE_SUMMARY.md')
        
        # í†µê³„ ê³„ì‚°
        non_pl_jobs = [j for j in jobs_data if j.get('group') == 'Non-PL']
        pl_jobs = [j for j in jobs_data if j.get('group') == 'PL']
        
        # ì§ì¢…ë³„ ì§‘ê³„
        job_type_stats = {}
        for job in jobs_data:
            job_type = job.get('job_type', 'ë¯¸ë¶„ë¥˜')
            if job_type not in job_type_stats:
                job_type_stats[job_type] = []
            job_type_stats[job_type].append(job.get('job_title', ''))
        
        # ë¦¬í¬íŠ¸ ì‘ì„±
        report = f"""# OKê¸ˆìœµê·¸ë£¹ ì§ë¬´ê¸°ìˆ ì„œ ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ

## ğŸ“Š ìµœì¢… ê²°ê³¼
- **ì¶”ì¶œ ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ì´ ì§ë¬´ ìˆ˜**: {len(jobs_data)}ê°œ
  - Non-PL ì§êµ°: {len(non_pl_jobs)}ê°œ
  - PL ì§êµ°: {len(pl_jobs)}ê°œ

## ğŸ“‹ ì§ì¢…ë³„ ìƒì„¸ í˜„í™©

### Non-PL ì§êµ° (8ê°œ ì§ì¢…, 33ê°œ ì§ë¬´)
"""
        
        # Non-PL ì§ì¢…ë³„ ì¶œë ¥
        for job_type, jobs in sorted(job_type_stats.items()):
            job_list = [j for j in jobs_data if j.get('job_type') == job_type and j.get('group') == 'Non-PL']
            if job_list:
                report += f"\n#### {job_type} ({len(job_list)}ê°œ)\n"
                for job in job_list:
                    report += f"- {job['job_title']}\n"
        
        report += "\n### PL ì§êµ° (1ê°œ ì§ì¢…, 4ê°œ ì§ë¬´)\n"
        
        # PL ì§ì¢…ë³„ ì¶œë ¥
        for job_type, jobs in sorted(job_type_stats.items()):
            job_list = [j for j in jobs_data if j.get('job_type') == job_type and j.get('group') == 'PL']
            if job_list:
                report += f"\n#### {job_type} ({len(job_list)}ê°œ)\n"
                for job in job_list:
                    report += f"- {job['job_title']}\n"
        
        report += f"""
## âœ… ê²€ì¦ ê²°ê³¼
- PDF ëª…ì‹œ: Non-PL 33ê°œ + PL 4ê°œ = ì´ 37ê°œ
- ì‹¤ì œ ì¶”ì¶œ: {len(jobs_data)}ê°œ
- **ìƒíƒœ**: {'âœ… ì™„ì „ ì¼ì¹˜' if len(jobs_data) == 37 else 'âš ï¸ ë¶ˆì¼ì¹˜'}

## ğŸ“ ìƒì„±ëœ íŒŒì¼
1. Excel: `excel/OKê¸ˆìœµê·¸ë£¹_ì§ë¬´ê¸°ìˆ ì„œ_ì „ì²´_*.xlsx`
2. JSON: `json/ok_job_profiles_complete.json`
3. ë¡œê·¸: `logs/migration_*.log`

---
*OK Job Profile Complete Migration Tool*
"""
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        self.logger.info(f"ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±: {report_file}")
        return report_file


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    pdf_path = r"C:/Users/apro/OneDrive/Desktop/ì„¤ëª…íšŒìë£Œ/OK_Job Profile.pdf"
    output_dir = r"C:/Users/apro/OneDrive/Desktop/ì„¤ëª…íšŒìë£Œ/job_profile_complete"
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    # ë¡œê¹… ì„¤ì •
    logger = setup_logging(output_dir)
    logger.info("="*60)
    logger.info("OKê¸ˆìœµê·¸ë£¹ ì§ë¬´ê¸°ìˆ ì„œ ì™„ì „ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
    logger.info("ëª©í‘œ: Non-PL 33ê°œ + PL 4ê°œ = ì´ 37ê°œ ì§ë¬´")
    logger.info("="*60)
    
    try:
        # 1. PDF íŒŒì‹±
        parser = CompleteJobProfileParser(pdf_path, output_dir)
        jobs_data = parser.parse_all()
        
        # 2. ë°ì´í„° ë‚´ë³´ë‚´ê¸°
        exporter = JobDataExporter(output_dir)
        excel_file = exporter.export_to_excel(jobs_data)
        json_file = exporter.export_to_json(jobs_data)
        report_file = exporter.generate_summary_report(jobs_data)
        
        # ì™„ë£Œ
        logger.info("="*60)
        logger.info("ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        logger.info("="*60)
        
        print(f"\nâœ… OKê¸ˆìœµê·¸ë£¹ ì§ë¬´ê¸°ìˆ ì„œ ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        print(f"ğŸ“Š ì¶”ì¶œ ê²°ê³¼: {len(jobs_data)}ê°œ ì§ë¬´ / ëª©í‘œ 37ê°œ")
        print(f"ğŸ“ ì¶œë ¥ ìœ„ì¹˜: {output_dir}")
        print(f"ğŸ“„ Excel: {os.path.basename(excel_file)}")
        print(f"ğŸ’¾ JSON: {os.path.basename(json_file)}")
        print(f"ğŸ“‹ ë¦¬í¬íŠ¸: {os.path.basename(report_file)}")
        
    except Exception as e:
        logger.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


if __name__ == '__main__':
    main()