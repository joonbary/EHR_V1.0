#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
OKê¸ˆìœµê·¸ë£¹ ì§ë¬´ê¸°ìˆ ì„œ PDF íŒŒì‹± ë° ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ìë™í™” ìŠ¤í¬ë¦½íŠ¸ v2

PDF êµ¬ì¡°ì— ë§ì¶˜ ê°œì„ ëœ íŒŒì‹± ë¡œì§
"""

import os
import sys
import io
import json
import re
import logging
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import pandas as pd
from tqdm import tqdm
import fitz  # PyMuPDF
import openpyxl
from openpyxl.styles import Font, PatternFill, Alignment

# í•œê¸€ ì¶œë ¥ ì„¤ì •
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# ë¡œê¹… ì„¤ì •
def setup_logging(output_dir: str):
    """ë¡œê¹… ì„¤ì •"""
    log_dir = os.path.join(output_dir, 'logs')
    os.makedirs(log_dir, exist_ok=True)
    
    log_file = os.path.join(log_dir, f'migration_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    return logging.getLogger(__name__)


class JobProfilePDFParser:
    """OKê¸ˆìœµê·¸ë£¹ ì§ë¬´ê¸°ìˆ ì„œ PDF íŒŒì„œ"""
    
    def __init__(self, pdf_path: str, output_dir: str):
        self.pdf_path = pdf_path
        self.output_dir = output_dir
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # OKê¸ˆìœµê·¸ë£¹ ì§ë¬´ë¶„ë¥˜ì²´ê³„
        self.job_categories = {
            'ITê¸°íš': {
                'id': 'it_planning',
                'category': 'IT/ë””ì§€í„¸',
                'jobs': ['ì‹œìŠ¤í…œê¸°íš']
            },
            'ITê°œë°œ': {
                'id': 'it_development',
                'category': 'IT/ë””ì§€í„¸',
                'jobs': ['ì‹œìŠ¤í…œê°œë°œ']
            },
            'ITìš´ì˜': {
                'id': 'it_operation',
                'category': 'IT/ë””ì§€í„¸',
                'jobs': ['ì‹œìŠ¤í…œê´€ë¦¬', 'ì„œë¹„ìŠ¤ìš´ì˜']
            },
            'ê²½ì˜ê´€ë¦¬': {
                'id': 'management',
                'category': 'ê²½ì˜ì§€ì›',
                'jobs': ['ê°ì‚¬', 'HRM', 'HRD', 'ê²½ì˜ì§€ì›', 'ë¹„ì„œ', 'PR', 'ê²½ì˜ê¸°íš', 
                         'ë””ìì¸', 'ë¦¬ìŠ¤í¬ê´€ë¦¬', 'ë§ˆì¼€íŒ…', 'ìŠ¤í¬ì¸ ì‚¬ë¬´ê´€ë¦¬', 'ìê¸ˆ', 
                         'ì¬ë¬´íšŒê³„', 'ì •ë³´ë³´ì•ˆ', 'ì¤€ë²•ì§€ì›', 'ì´ë¬´']
            },
            'íˆ¬ìê¸ˆìœµ': {
                'id': 'investment',
                'category': 'ì˜ì—…/ë§ˆì¼€íŒ…',
                'jobs': ['IBê¸ˆìœµ']
            },
            'ê¸°ì—…ê¸ˆìœµ': {
                'id': 'corporate_finance',
                'category': 'ì˜ì—…/ë§ˆì¼€íŒ…',
                'jobs': ['ê¸°ì—…ì˜ì—…ê¸°íš', 'ê¸°ì—…ì—¬ì‹ ì‹¬ì‚¬', 'ê¸°ì—…ì—¬ì‹ ê´€ë¦¬']
            },
            'ê¸°ì—…ì˜ì—…': {
                'id': 'corporate_sales',
                'category': 'ì˜ì—…/ë§ˆì¼€íŒ…',
                'jobs': ['ì—¬ì‹ ì˜ì—…']
            },
            'ë¦¬í…Œì¼ê¸ˆìœµ': {
                'id': 'retail_finance',
                'category': 'ì˜ì—…/ë§ˆì¼€íŒ…',
                'jobs': ['ë°ì´í„°/í†µê³„', 'í”Œë«í¼/í•€í…Œí¬', 'NPLì˜ì—…ê¸°íš', 'ë¦¬í…Œì¼ì‹¬ì‚¬ê¸°íš', 
                         'PLê¸°íš', 'ëª¨ê¸°ì§€ê¸°íš', 'ìˆ˜ì‹ ê¸°íš', 'ìˆ˜ì‹ ì˜ì—…']
            },
            'ê³ ê°ì§€ì›': {
                'id': 'customer_support',
                'category': 'ì˜ì—…/ë§ˆì¼€íŒ…',
                'jobs': ['ì—¬ì‹ ê³ ê°ì§€ì›', 'ì‚¬ë¬´ì§€ì›', 'ìˆ˜ì‹ ê³ ê°ì§€ì›', 'ì±„ê¶Œê´€ë¦¬ì§€ì›']
            }
        }
        
        self.parsed_jobs = []
        self.validation_errors = []
    
    def extract_text_from_pdf(self) -> List[Tuple[int, str]]:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        self.logger.info(f"PDF íŒŒì¼ ì½ê¸° ì‹œì‘: {self.pdf_path}")
        
        try:
            doc = fitz.open(self.pdf_path)
            pages_text = []
            
            for page_num in range(len(doc)):
                page = doc[page_num]
                text = page.get_text()
                pages_text.append((page_num + 1, text))
                
            doc.close()
            self.logger.info(f"ì´ {len(pages_text)}í˜ì´ì§€ ì¶”ì¶œ ì™„ë£Œ")
            return pages_text
            
        except Exception as e:
            self.logger.error(f"PDF ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            raise
    
    def parse_job_from_pages(self, pages_text: List[Tuple[int, str]]) -> List[Dict]:
        """í˜ì´ì§€ì—ì„œ ì§ë¬´ ì •ë³´ íŒŒì‹±"""
        jobs = []
        current_job = None
        
        for page_num, text in pages_text:
            lines = text.strip().split('\n')
            
            # ì§ë¬´ ì‹œì‘ í˜ì´ì§€ ê°ì§€ (ì˜ˆ: "ì§ë¬´: ì‹œìŠ¤í…œê¸°íš")
            for i, line in enumerate(lines):
                if line.startswith('ì§ë¬´:'):
                    # ì´ì „ ì§ë¬´ ì €ì¥
                    if current_job:
                        jobs.append(current_job)
                    
                    # ìƒˆ ì§ë¬´ ì‹œì‘
                    job_name = line.replace('ì§ë¬´:', '').strip()
                    self.logger.info(f"í˜ì´ì§€ {page_num}: ì§ë¬´ ë°œê²¬ - {job_name}")
                    
                    current_job = {
                        'job_title': job_name,
                        'page_number': page_num,
                        'raw_text': '',
                        'responsibilities': [],
                        'qualifications': {
                            'basic': [],
                            'advanced': []
                        }
                    }
                    
                    # ì´ì „ í˜ì´ì§€ì—ì„œ ì§ì¢… ì •ë³´ ì°¾ê¸°
                    if page_num > 1:
                        prev_text = pages_text[page_num - 2][1] if page_num >= 2 else ''
                        job_type_match = re.search(r'ì§ì¢…([^\n]+)', prev_text)
                        if job_type_match:
                            job_type = job_type_match.group(1).strip()
                            current_job['job_type'] = job_type
                            
                            # ì§êµ° ë§¤í•‘
                            for type_key, type_info in self.job_categories.items():
                                if type_key in job_type:
                                    current_job['job_category'] = type_info['category']
                                    current_job['category_id'] = type_info['id']
                                    current_job['mapped_type'] = type_key
                                    break
            
            # í˜„ì¬ ì§ë¬´ê°€ ìˆìœ¼ë©´ ë‚´ìš© íŒŒì‹±
            if current_job:
                current_job['raw_text'] += text + '\n'
                
                # í•µì‹¬ì—­í• &ì±…ì„ íŒŒì‹±
                if 'í•µì‹¬ì—­í• &ì±…ì„' in text:
                    # í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ë˜ì–´ ìˆëŠ” ì—­í• ê³¼ ì±…ì„ íŒŒì‹±
                    in_responsibility = False
                    for line in lines:
                        if 'í•µì‹¬ì—­í• &ì±…ì„' in line and 'ì •ì˜' in line:
                            in_responsibility = True
                            continue
                        
                        if in_responsibility and line.strip():
                            # ë¹ˆ ì¤„ì´ë‚˜ ë‹¤ìŒ ì„¹ì…˜ ì‹œì‘ê¹Œì§€
                            if 'ê¸°ë³¸ê¸°ìˆ &ì§€ì‹' in line or 'ì‘ìš©ê¸°ìˆ &ì§€ì‹' in line:
                                in_responsibility = False
                                break
                            
                            # ì—­í• ëª…ê³¼ ì„¤ëª… ë¶„ë¦¬
                            parts = line.split(maxsplit=1)
                            if len(parts) >= 2 and not any(keyword in parts[0] for keyword in ['ì •ì˜', 'í•µì‹¬ì—­í• ']):
                                role_desc = parts[1] if len(parts) > 1 else line
                                if len(role_desc) > 20:  # ì˜ë¯¸ìˆëŠ” ì„¤ëª…ë§Œ
                                    current_job['responsibilities'].append(role_desc)
                
                # ê¸°ìˆ &ì§€ì‹ íŒŒì‹±
                if 'ê¸°ë³¸ê¸°ìˆ &ì§€ì‹' in text:
                    section_text = text[text.find('ê¸°ë³¸ê¸°ìˆ &ì§€ì‹'):]
                    if 'ì‘ìš©ê¸°ìˆ &ì§€ì‹' in section_text:
                        basic_section = section_text[:section_text.find('ì‘ìš©ê¸°ìˆ &ì§€ì‹')]
                    else:
                        basic_section = section_text
                    
                    # ê¸°ë³¸ ê¸°ìˆ  ì¶”ì¶œ
                    skill_lines = basic_section.split('\n')
                    for line in skill_lines[1:]:  # í—¤ë” ì œì™¸
                        if line.strip() and len(line) > 10 and 'ì •ì˜' not in line:
                            if not any(keyword in line for keyword in ['ê¸°ë³¸ê¸°ìˆ &ì§€ì‹', 'ì‘ìš©ê¸°ìˆ &ì§€ì‹', 'ì§ë¬´:']):
                                current_job['qualifications']['basic'].append(line.strip())
                
                if 'ì‘ìš©ê¸°ìˆ &ì§€ì‹' in text:
                    section_text = text[text.find('ì‘ìš©ê¸°ìˆ &ì§€ì‹'):]
                    skill_lines = section_text.split('\n')
                    for line in skill_lines[1:]:  # í—¤ë” ì œì™¸
                        if line.strip() and len(line) > 10 and 'ì •ì˜' not in line:
                            if not any(keyword in line for keyword in ['ê¸°ë³¸ê¸°ìˆ &ì§€ì‹', 'ì‘ìš©ê¸°ìˆ &ì§€ì‹', 'ì§ë¬´:', 'Job Profile']):
                                current_job['qualifications']['advanced'].append(line.strip())
        
        # ë§ˆì§€ë§‰ ì§ë¬´ ì €ì¥
        if current_job:
            jobs.append(current_job)
        
        return jobs
    
    def validate_job_data(self, job_data: Dict) -> Tuple[bool, List[str]]:
        """ì§ë¬´ ë°ì´í„° ê²€ì¦"""
        errors = []
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        if not job_data.get('job_title'):
            errors.append("ì§ë¬´ëª… ëˆ„ë½")
        
        if not job_data.get('responsibilities'):
            errors.append("ì—­í•  ë° ì±…ì„ ëˆ„ë½")
        elif len(job_data['responsibilities']) < 2:
            errors.append("ì—­í•  ë° ì±…ì„ì´ 2ê°œ ë¯¸ë§Œ")
        
        if not job_data.get('qualifications'):
            errors.append("ìê²©ìš”ê±´ ëˆ„ë½")
        else:
            basic_skills = job_data['qualifications'].get('basic', [])
            advanced_skills = job_data['qualifications'].get('advanced', [])
            if len(basic_skills) + len(advanced_skills) < 2:
                errors.append("ê¸°ìˆ /ì§€ì‹ ìš”ê±´ì´ 2ê°œ ë¯¸ë§Œ")
        
        # ì§ë¬´ë¶„ë¥˜ ë§¤í•‘ ê²€ì¦
        if not job_data.get('job_category'):
            errors.append("ì§êµ° ë¶„ë¥˜ ëˆ„ë½")
        
        is_valid = len(errors) == 0
        return is_valid, errors
    
    def parse_all_jobs(self) -> List[Dict]:
        """ì „ì²´ PDF íŒŒì‹± ì‹¤í–‰"""
        self.logger.info("ì§ë¬´ê¸°ìˆ ì„œ íŒŒì‹± ì‹œì‘")
        
        # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
        pages_text = self.extract_text_from_pdf()
        
        # ì§ë¬´ ì •ë³´ íŒŒì‹±
        jobs = self.parse_job_from_pages(pages_text)
        
        # ê²€ì¦ ë° ì •ë¦¬
        with tqdm(total=len(jobs), desc="ì§ë¬´ ê²€ì¦") as pbar:
            for job in jobs:
                # ê²€ì¦
                is_valid, errors = self.validate_job_data(job)
                job['is_valid'] = is_valid
                job['validation_errors'] = errors
                
                if not is_valid:
                    self.logger.warning(f"ê²€ì¦ ì‹¤íŒ¨ - {job.get('job_title', 'Unknown')}: {errors}")
                
                self.parsed_jobs.append(job)
                pbar.update(1)
        
        self.logger.info(f"ì´ {len(self.parsed_jobs)}ê°œ ì§ë¬´ íŒŒì‹± ì™„ë£Œ")
        valid_count = sum(1 for job in self.parsed_jobs if job['is_valid'])
        self.logger.info(f"ìœ íš¨í•œ ì§ë¬´: {valid_count}ê°œ")
        
        return self.parsed_jobs


class JobProfileMigrator:
    """ì§ë¬´ê¸°ìˆ ì„œ ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜"""
    
    def __init__(self, output_dir: str):
        self.output_dir = output_dir
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # Django ì„¤ì •
        os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'ehr_system.settings')
        import django
        django.setup()
    
    def migrate_to_database(self, jobs_data: List[Dict]) -> Dict[str, int]:
        """Django ë°ì´í„°ë² ì´ìŠ¤ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜"""
        from job_profiles.models import JobCategory, JobType, JobRole, JobProfile
        from django.db import transaction
        
        stats = {
            'categories_created': 0,
            'types_created': 0,
            'roles_created': 0,
            'profiles_created': 0,
            'errors': 0
        }
        
        self.logger.info("ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
        
        # ì§êµ°/ì§ì¢… ìƒì„±
        categories_map = {}
        types_map = {}
        
        with transaction.atomic():
            # ì§êµ° ìƒì„± (IT/ë””ì§€í„¸, ê²½ì˜ì§€ì›, ì˜ì—…/ë§ˆì¼€íŒ…)
            main_categories = {
                'IT/ë””ì§€í„¸': 'it_digital',
                'ê²½ì˜ì§€ì›': 'management_support',
                'ì˜ì—…/ë§ˆì¼€íŒ…': 'sales_marketing'
            }
            
            for cat_name, cat_id in main_categories.items():
                category, created = JobCategory.objects.get_or_create(
                    name=cat_name,
                    defaults={'is_active': True}
                )
                categories_map[cat_name] = category
                if created:
                    stats['categories_created'] += 1
                    self.logger.info(f"ì§êµ° ìƒì„±: {cat_name}")
        
        # ì§ë¬´ë³„ ì²˜ë¦¬
        with tqdm(total=len(jobs_data), desc="DB ë§ˆì´ê·¸ë ˆì´ì…˜") as pbar:
            for job_data in jobs_data:
                try:
                    if not job_data['is_valid']:
                        self.logger.warning(f"ê²€ì¦ ì‹¤íŒ¨ë¡œ ê±´ë„ˆëœ€: {job_data.get('job_title')}")
                        stats['errors'] += 1
                        pbar.update(1)
                        continue
                    
                    with transaction.atomic():
                        # ì§êµ° ê°€ì ¸ì˜¤ê¸°
                        category_name = job_data.get('job_category', 'ê²½ì˜ì§€ì›')
                        category = categories_map.get(category_name)
                        if not category:
                            self.logger.error(f"ì§êµ°ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {category_name}")
                            stats['errors'] += 1
                            pbar.update(1)
                            continue
                        
                        # ì§ì¢… ìƒì„±
                        job_type_name = job_data.get('mapped_type', job_data.get('job_type', 'ê¸°íƒ€'))
                        job_type, created = JobType.objects.get_or_create(
                            category=category,
                            name=job_type_name,
                            defaults={'is_active': True}
                        )
                        if created:
                            stats['types_created'] += 1
                            self.logger.info(f"ì§ì¢… ìƒì„±: {job_type_name}")
                        
                        # ì§ë¬´ ì—­í•  ìƒì„±
                        job_role, created = JobRole.objects.get_or_create(
                            job_type=job_type,
                            name=job_data['job_title'],
                            defaults={'is_active': True}
                        )
                        if created:
                            stats['roles_created'] += 1
                        
                        # ì§ë¬´ í”„ë¡œí•„ ìƒì„±
                        responsibilities_text = '\n'.join(job_data.get('responsibilities', []))
                        
                        # ìê²©ìš”ê±´ í†µí•©
                        qualifications = []
                        basic_skills = job_data.get('qualifications', {}).get('basic', [])
                        advanced_skills = job_data.get('qualifications', {}).get('advanced', [])
                        
                        if basic_skills:
                            qualifications.append('[ê¸°ë³¸ ê¸°ìˆ /ì§€ì‹]')
                            qualifications.extend(basic_skills)
                        
                        if advanced_skills:
                            qualifications.append('\n[ì‘ìš© ê¸°ìˆ /ì§€ì‹]')
                            qualifications.extend(advanced_skills)
                        
                        qualifications_text = '\n'.join(qualifications)
                        
                        job_profile, created = JobProfile.objects.update_or_create(
                            job_role=job_role,
                            defaults={
                                'role_responsibility': responsibilities_text,
                                'qualification': qualifications_text,
                                'is_active': True
                            }
                        )
                        
                        if created:
                            stats['profiles_created'] += 1
                            self.logger.info(f"ìƒì„±ë¨: {job_data['job_title']}")
                        else:
                            self.logger.info(f"ì—…ë°ì´íŠ¸ë¨: {job_data['job_title']}")
                
                except Exception as e:
                    self.logger.error(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜¤ë¥˜ - {job_data.get('job_title')}: {str(e)}")
                    stats['errors'] += 1
                
                pbar.update(1)
        
        self.logger.info(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: {stats}")
        return stats
    
    def export_to_json(self, jobs_data: List[Dict]) -> str:
        """JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        json_dir = os.path.join(self.output_dir, 'json')
        os.makedirs(json_dir, exist_ok=True)
        
        # raw_text ì œê±° (íŒŒì¼ í¬ê¸° ì¤„ì´ê¸°)
        clean_jobs = []
        for job in jobs_data:
            clean_job = {k: v for k, v in job.items() if k != 'raw_text'}
            clean_jobs.append(clean_job)
        
        # ì „ì²´ ë°ì´í„°
        all_jobs_file = os.path.join(json_dir, 'all_job_profiles.json')
        with open(all_jobs_file, 'w', encoding='utf-8') as f:
            json.dump(clean_jobs, f, ensure_ascii=False, indent=2)
        
        # ì§êµ°ë³„ ë¶„ë¦¬
        by_category = {}
        for job in clean_jobs:
            category = job.get('job_category', 'ë¯¸ë¶„ë¥˜')
            if category not in by_category:
                by_category[category] = []
            by_category[category].append(job)
        
        for category, jobs in by_category.items():
            category_file = os.path.join(json_dir, f'{category.replace("/", "_")}_jobs.json')
            with open(category_file, 'w', encoding='utf-8') as f:
                json.dump(jobs, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"JSON ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {json_dir}")
        return all_jobs_file
    
    def export_to_excel(self, jobs_data: List[Dict]) -> str:
        """Excel íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        excel_dir = os.path.join(self.output_dir, 'excel')
        os.makedirs(excel_dir, exist_ok=True)
        
        excel_file = os.path.join(excel_dir, 'ok_job_profiles.xlsx')
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df_data = []
        for job in jobs_data:
            # ìê²©ìš”ê±´ ì •ë¦¬
            basic_skills = '\n'.join(job.get('qualifications', {}).get('basic', []))
            advanced_skills = '\n'.join(job.get('qualifications', {}).get('advanced', []))
            
            df_data.append({
                'í˜ì´ì§€': job.get('page_number', ''),
                'ì§êµ°': job.get('job_category', ''),
                'ì§ì¢…': job.get('mapped_type', job.get('job_type', '')),
                'ì§ë¬´ëª…': job.get('job_title', ''),
                'ì—­í•  ë° ì±…ì„': '\n'.join(job.get('responsibilities', [])),
                'ê¸°ë³¸ ê¸°ìˆ /ì§€ì‹': basic_skills,
                'ì‘ìš© ê¸°ìˆ /ì§€ì‹': advanced_skills,
                'ê²€ì¦ìƒíƒœ': 'ìœ íš¨' if job.get('is_valid') else 'ê²€ì¦ì‹¤íŒ¨',
                'ê²€ì¦ì˜¤ë¥˜': ', '.join(job.get('validation_errors', []))
            })
        
        df = pd.DataFrame(df_data)
        
        # Excel Writer
        with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
            # ì „ì²´ ë°ì´í„° ì‹œíŠ¸
            df.to_excel(writer, sheet_name='ì „ì²´ì§ë¬´', index=False)
            
            # ì§êµ°ë³„ ì‹œíŠ¸
            for category in df['ì§êµ°'].unique():
                if pd.notna(category):
                    category_df = df[df['ì§êµ°'] == category]
                    sheet_name = category.replace('/', '_')[:31]  # Excel ì‹œíŠ¸ëª… ì œí•œ
                    category_df.to_excel(writer, sheet_name=sheet_name, index=False)
            
            # ê²€ì¦ ì‹¤íŒ¨ ì‹œíŠ¸
            invalid_df = df[df['ê²€ì¦ìƒíƒœ'] == 'ê²€ì¦ì‹¤íŒ¨']
            if not invalid_df.empty:
                invalid_df.to_excel(writer, sheet_name='ê²€ì¦ì‹¤íŒ¨', index=False)
        
        # ìŠ¤íƒ€ì¼ ì ìš©
        wb = openpyxl.load_workbook(excel_file)
        
        for sheet_name in wb.sheetnames:
            ws = wb[sheet_name]
            
            # í—¤ë” ìŠ¤íƒ€ì¼
            header_fill = PatternFill(start_color='366092', end_color='366092', fill_type='solid')
            header_font = Font(color='FFFFFF', bold=True)
            
            for cell in ws[1]:
                cell.fill = header_fill
                cell.font = header_font
                cell.alignment = Alignment(horizontal='center', vertical='center')
            
            # ì—´ ë„ˆë¹„ ìë™ ì¡°ì •
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                
                adjusted_width = min(max_length + 2, 50)
                ws.column_dimensions[column_letter].width = adjusted_width
            
            # í–‰ ë†’ì´ ì¡°ì • (ê¸´ í…ìŠ¤íŠ¸ìš©)
            for row in ws.iter_rows(min_row=2):
                for cell in row:
                    if cell.value and '\n' in str(cell.value):
                        ws.row_dimensions[cell.row].height = 80
                        cell.alignment = Alignment(wrap_text=True, vertical='top')
        
        wb.save(excel_file)
        self.logger.info(f"Excel ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {excel_file}")
        return excel_file
    
    def generate_migration_report(self, jobs_data: List[Dict], stats: Dict) -> str:
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ë¦¬í¬íŠ¸ ìƒì„±"""
        report_file = os.path.join(self.output_dir, 'migration_report.md')
        
        # í†µê³„ ê³„ì‚°
        total_jobs = len(jobs_data)
        valid_jobs = sum(1 for job in jobs_data if job['is_valid'])
        invalid_jobs = total_jobs - valid_jobs
        
        # ì§êµ°ë³„ í†µê³„
        category_stats = {}
        for job in jobs_data:
            category = job.get('job_category', 'ë¯¸ë¶„ë¥˜')
            if category not in category_stats:
                category_stats[category] = {'total': 0, 'valid': 0}
            category_stats[category]['total'] += 1
            if job['is_valid']:
                category_stats[category]['valid'] += 1
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report_content = f"""# OKê¸ˆìœµê·¸ë£¹ ì§ë¬´ê¸°ìˆ ì„œ ë§ˆì´ê·¸ë ˆì´ì…˜ ë¦¬í¬íŠ¸

## ğŸ“Š ì „ì²´ ìš”ì•½
- ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- PDF íŒŒì¼: OK_Job Profile.pdf
- ì´ ì§ë¬´ ìˆ˜: {total_jobs}ê°œ
- ìœ íš¨ ì§ë¬´: {valid_jobs}ê°œ ({valid_jobs/total_jobs*100:.1f}%)
- ê²€ì¦ ì‹¤íŒ¨: {invalid_jobs}ê°œ

## ğŸ“ˆ ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼
- ì§êµ° ìƒì„±: {stats.get('categories_created', 0)}ê°œ
- ì§ì¢… ìƒì„±: {stats.get('types_created', 0)}ê°œ
- ì§ë¬´ ìƒì„±: {stats.get('roles_created', 0)}ê°œ
- í”„ë¡œí•„ ìƒì„±: {stats.get('profiles_created', 0)}ê°œ
- ì˜¤ë¥˜ ë°œìƒ: {stats.get('errors', 0)}ê±´

## ğŸ“ ì§êµ°ë³„ í˜„í™©
"""
        
        for category, stat in sorted(category_stats.items()):
            report_content += f"""
### {category}
- ì´ ì§ë¬´: {stat['total']}ê°œ
- ìœ íš¨: {stat['valid']}ê°œ ({stat['valid']/stat['total']*100:.1f}%)
"""
        
        # ê²€ì¦ ì‹¤íŒ¨ ìƒì„¸
        if invalid_jobs > 0:
            report_content += "\n## âš ï¸ ê²€ì¦ ì‹¤íŒ¨ ì§ë¬´\n"
            for job in jobs_data:
                if not job['is_valid']:
                    errors = ', '.join(job['validation_errors'])
                    report_content += f"- {job.get('job_title', 'Unknown')}: {errors}\n"
        
        # íŒŒì‹±ëœ ì§ë¬´ ëª©ë¡
        report_content += "\n## ğŸ“‹ íŒŒì‹±ëœ ì§ë¬´ ëª©ë¡\n"
        for i, job in enumerate(jobs_data, 1):
            status = "âœ…" if job['is_valid'] else "âŒ"
            report_content += f"{i}. {status} {job.get('job_title', 'Unknown')} "
            report_content += f"({job.get('job_category', 'ë¯¸ë¶„ë¥˜')} > {job.get('mapped_type', 'ë¯¸ë¶„ë¥˜')})\n"
        
        # ì¶œë ¥ íŒŒì¼ ì •ë³´
        report_content += f"""
## ğŸ“¤ ì¶œë ¥ íŒŒì¼
- JSON: {self.output_dir}/json/all_job_profiles.json
- Excel: {self.output_dir}/excel/ok_job_profiles.xlsx
- ë¡œê·¸: {self.output_dir}/logs/

## âœ… ë‹¤ìŒ ë‹¨ê³„
1. Excel íŒŒì¼ì—ì„œ ê²€ì¦ ì‹¤íŒ¨ ì§ë¬´ í™•ì¸ ë° ìˆ˜ë™ ìˆ˜ì •
2. ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
3. í”„ë¡œë•ì…˜ í™˜ê²½ ì ìš©
"""
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        self.logger.info(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ë¦¬í¬íŠ¸ ìƒì„±: {report_file}")
        return report_file


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ì„¤ì •
    pdf_path = r"C:/Users/apro/OneDrive/Desktop/ì„¤ëª…íšŒìë£Œ/OK_Job Profile.pdf"
    output_dir = r"C:/Users/apro/OneDrive/Desktop/ì„¤ëª…íšŒìë£Œ/job_profile_migrated"
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    # ë¡œê¹… ì„¤ì •
    logger = setup_logging(output_dir)
    logger.info("="*60)
    logger.info("OKê¸ˆìœµê·¸ë£¹ ì§ë¬´ê¸°ìˆ ì„œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
    logger.info("="*60)
    
    try:
        # 1. PDF íŒŒì‹±
        parser = JobProfilePDFParser(pdf_path, output_dir)
        jobs_data = parser.parse_all_jobs()
        
        if not jobs_data:
            logger.error("íŒŒì‹±ëœ ì§ë¬´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 2. ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜
        migrator = JobProfileMigrator(output_dir)
        
        # Django í™˜ê²½ í™•ì¸
        try:
            stats = migrator.migrate_to_database(jobs_data)
        except Exception as e:
            logger.warning(f"ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {str(e)}")
            logger.info("JSON/Excel ë‚´ë³´ë‚´ê¸°ë§Œ ì§„í–‰í•©ë‹ˆë‹¤.")
            stats = {'errors': len(jobs_data)}
        
        # 3. JSON ë‚´ë³´ë‚´ê¸°
        json_file = migrator.export_to_json(jobs_data)
        
        # 4. Excel ë‚´ë³´ë‚´ê¸°
        excel_file = migrator.export_to_excel(jobs_data)
        
        # 5. ë¦¬í¬íŠ¸ ìƒì„±
        report_file = migrator.generate_migration_report(jobs_data, stats)
        
        # ì™„ë£Œ ë©”ì‹œì§€
        logger.info("="*60)
        logger.info("ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        logger.info(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
        logger.info(f"ë¦¬í¬íŠ¸ í™•ì¸: {report_file}")
        logger.info("="*60)
        
        # ê²°ê³¼ ì¶œë ¥
        print("\nâœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
        print(f"ğŸ“„ JSON: {json_file}")
        print(f"ğŸ“Š Excel: {excel_file}")
        print(f"ğŸ“‹ ë¦¬í¬íŠ¸: {report_file}")
        
    except Exception as e:
        logger.error(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        raise


if __name__ == '__main__':
    main()