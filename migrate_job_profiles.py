#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
OKê¸ˆìœµê·¸ë£¹ ì§ë¬´ê¸°ìˆ ì„œ PDF íŒŒì‹± ë° ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ìë™í™” ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
1. PDFì—ì„œ ì§ë¬´ë³„ ì„¹ì…˜ ìë™ ê°ì§€ ë° ë¶„ë¦¬
2. ì§ë¬´ ì •ë³´ êµ¬ì¡°í™” (ì§êµ°/ì§ì¢…/ì§ë¬´/ì—­í• /ìê²©ìš”ê±´)
3. OKê¸ˆìœµê·¸ë£¹ ì§ë¬´ë¶„ë¥˜ì²´ê³„ ë§¤í•‘
4. ë°ì´í„° ê²€ì¦ ë° ì •ì œ
5. Django ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜
6. JSON/Excel ë°±ì—… ìƒì„±
"""

import os
import sys
import io
import json
import re
import logging
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import pandas as pd
from tqdm import tqdm
import fitz  # PyMuPDF
import openpyxl
from openpyxl.styles import Font, PatternFill, Alignment

# í•œê¸€ ì¶œë ¥ ì„¤ì •
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# ë¡œê¹… ì„¤ì •
def setup_logging(output_dir: str):
    """ë¡œê¹… ì„¤ì •"""
    log_dir = os.path.join(output_dir, 'logs')
    os.makedirs(log_dir, exist_ok=True)
    
    log_file = os.path.join(log_dir, f'migration_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    return logging.getLogger(__name__)


class JobProfilePDFParser:
    """OKê¸ˆìœµê·¸ë£¹ ì§ë¬´ê¸°ìˆ ì„œ PDF íŒŒì„œ"""
    
    def __init__(self, pdf_path: str, output_dir: str):
        self.pdf_path = pdf_path
        self.output_dir = output_dir
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # OKê¸ˆìœµê·¸ë£¹ ì§ë¬´ë¶„ë¥˜ì²´ê³„
        self.job_categories = {
            'IT/ë””ì§€í„¸': {
                'id': 'it_digital',
                'job_types': {
                    'ì‹œìŠ¤í…œê°œë°œ': ['ë°±ì—”ë“œê°œë°œ', 'í”„ë¡ íŠ¸ì—”ë“œê°œë°œ', 'í’€ìŠ¤íƒê°œë°œ', 'ëª¨ë°”ì¼ê°œë°œ'],
                    'ITê¸°íš': ['ITì „ëµê¸°íš', 'í”„ë¡œì íŠ¸ê´€ë¦¬', 'ë¹„ì¦ˆë‹ˆìŠ¤ë¶„ì„'],
                    'ë°ì´í„°': ['ë°ì´í„°ë¶„ì„', 'ë°ì´í„°ì—”ì§€ë‹ˆì–´ë§', 'AI/MLì—”ì§€ë‹ˆì–´'],
                    'ì •ë³´ë³´ì•ˆ': ['ë³´ì•ˆê´€ì œ', 'ë³´ì•ˆì»¨ì„¤íŒ…', 'ì¹¨í•´ëŒ€ì‘'],
                    'ITì¸í”„ë¼': ['ì‹œìŠ¤í…œì—”ì§€ë‹ˆì–´', 'ë„¤íŠ¸ì›Œí¬ì—”ì§€ë‹ˆì–´', 'í´ë¼ìš°ë“œì—”ì§€ë‹ˆì–´']
                }
            },
            'ê²½ì˜ì§€ì›': {
                'id': 'management_support',
                'job_types': {
                    'ì¸ì‚¬': ['ì¸ì‚¬ê¸°íš', 'ì¸ì¬ê°œë°œ', 'ì¡°ì§ë¬¸í™”', 'ë…¸ë¬´ê´€ë¦¬'],
                    'ì¬ë¬´': ['ì¬ë¬´ê¸°íš', 'ìê¸ˆê´€ë¦¬', 'íšŒê³„', 'ì„¸ë¬´'],
                    'ì´ë¬´': ['ì´ë¬´ê¸°íš', 'êµ¬ë§¤ê´€ë¦¬', 'ìì‚°ê´€ë¦¬'],
                    'ë²•ë¬´': ['ë²•ë¬´ì§€ì›', 'ì»´í”Œë¼ì´ì–¸ìŠ¤', 'ê³„ì•½ê´€ë¦¬'],
                    'í™ë³´': ['ëŒ€ì™¸í™ë³´', 'ë¸Œëœë“œê´€ë¦¬', 'ì‚¬ë‚´ì»¤ë®¤ë‹ˆì¼€ì´ì…˜']
                }
            },
            'ì˜ì—…/ë§ˆì¼€íŒ…': {
                'id': 'sales_marketing',
                'job_types': {
                    'ê°œì¸ì˜ì—…': ['ê°œì¸ê¸ˆìœµì˜ì—…', 'PBì˜ì—…', 'ë””ì§€í„¸ì˜ì—…'],
                    'ê¸°ì—…ì˜ì—…': ['ê¸°ì—…ê¸ˆìœµì˜ì—…', 'IBì˜ì—…', 'ê¸€ë¡œë²Œì˜ì—…'],
                    'ë§ˆì¼€íŒ…': ['ë§ˆì¼€íŒ…ì „ëµ', 'ë””ì§€í„¸ë§ˆì¼€íŒ…', 'ìƒí’ˆê¸°íš'],
                    'ê³ ê°ê´€ë¦¬': ['ê³ ê°ì„œë¹„ìŠ¤', 'CSê¸°íš', 'VOCê´€ë¦¬']
                }
            },
            'ë¦¬ìŠ¤í¬/ì‹¬ì‚¬': {
                'id': 'risk_audit',
                'job_types': {
                    'ë¦¬ìŠ¤í¬ê´€ë¦¬': ['ì‹ ìš©ë¦¬ìŠ¤í¬', 'ì‹œì¥ë¦¬ìŠ¤í¬', 'ìš´ì˜ë¦¬ìŠ¤í¬'],
                    'ì—¬ì‹ ì‹¬ì‚¬': ['ê°œì¸ì—¬ì‹ ì‹¬ì‚¬', 'ê¸°ì—…ì—¬ì‹ ì‹¬ì‚¬', 'ì‹¬ì‚¬ê¸°íš'],
                    'ê°ì‚¬': ['ë‚´ë¶€ê°ì‚¬', 'ì¤€ë²•ê°ì‹œ', 'ë¦¬ìŠ¤í¬ëª¨ë‹ˆí„°ë§']
                }
            }
        }
        
        # ì§ë¬´ ì •ë³´ íŒ¨í„´
        self.patterns = {
            'job_title': re.compile(r'^(?:ì§ë¬´ëª…|ì§ë¬´)\s*[:ï¼š]\s*(.+)$', re.MULTILINE),
            'job_category': re.compile(r'^(?:ì§êµ°|ë¶„ì•¼)\s*[:ï¼š]\s*(.+)$', re.MULTILINE),
            'job_type': re.compile(r'^(?:ì§ì¢…|ì§ë¬´êµ°)\s*[:ï¼š]\s*(.+)$', re.MULTILINE),
            'responsibility': re.compile(r'^(?:ì£¼ìš”\s*ì—…ë¬´|ë‹´ë‹¹ì—…ë¬´|ì—­í• )\s*[:ï¼š]?\s*\n((?:[-â€¢Â·]\s*.+\n?)+)', re.MULTILINE),
            'qualification': re.compile(r'^(?:ìê²©ìš”ê±´|í•„ìš”ì—­ëŸ‰|ìš”êµ¬ì‚¬í•­)\s*[:ï¼š]?\s*\n((?:[-â€¢Â·]\s*.+\n?)+)', re.MULTILINE),
            'preferred': re.compile(r'^(?:ìš°ëŒ€ì‚¬í•­|ìš°ëŒ€ì¡°ê±´)\s*[:ï¼š]?\s*\n((?:[-â€¢Â·]\s*.+\n?)+)', re.MULTILINE),
            'section_divider': re.compile(r'^[-=]{3,}|^[â”â”€]{3,}', re.MULTILINE)
        }
        
        self.parsed_jobs = []
        self.validation_errors = []
    
    def extract_text_from_pdf(self) -> List[Tuple[int, str]]:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        self.logger.info(f"PDF íŒŒì¼ ì½ê¸° ì‹œì‘: {self.pdf_path}")
        
        try:
            doc = fitz.open(self.pdf_path)
            pages_text = []
            
            for page_num in range(len(doc)):
                page = doc[page_num]
                text = page.get_text()
                pages_text.append((page_num + 1, text))
                
            doc.close()
            self.logger.info(f"ì´ {len(pages_text)}í˜ì´ì§€ ì¶”ì¶œ ì™„ë£Œ")
            return pages_text
            
        except Exception as e:
            self.logger.error(f"PDF ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            raise
    
    def detect_job_sections(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì§ë¬´ë³„ ì„¹ì…˜ ê°ì§€ ë° ë¶„ë¦¬"""
        # ì„¹ì…˜ êµ¬ë¶„ìë¡œ ë¶„ë¦¬
        sections = self.patterns['section_divider'].split(text)
        
        job_sections = []
        for section in sections:
            # ì§ë¬´ëª…ì´ í¬í•¨ëœ ì„¹ì…˜ë§Œ ì¶”ì¶œ
            if self.patterns['job_title'].search(section):
                job_sections.append(section.strip())
        
        self.logger.info(f"{len(job_sections)}ê°œì˜ ì§ë¬´ ì„¹ì…˜ ê°ì§€ë¨")
        return job_sections
    
    def parse_job_section(self, section: str, page_num: int) -> Optional[Dict]:
        """ê°œë³„ ì§ë¬´ ì„¹ì…˜ íŒŒì‹±"""
        job_data = {
            'page_number': page_num,
            'raw_text': section
        }
        
        # ì§ë¬´ëª… ì¶”ì¶œ
        job_title_match = self.patterns['job_title'].search(section)
        if job_title_match:
            job_data['job_title'] = job_title_match.group(1).strip()
        else:
            self.logger.warning(f"í˜ì´ì§€ {page_num}: ì§ë¬´ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return None
        
        # ì§êµ°/ì§ì¢… ì¶”ì¶œ
        category_match = self.patterns['job_category'].search(section)
        if category_match:
            job_data['job_category'] = category_match.group(1).strip()
        
        type_match = self.patterns['job_type'].search(section)
        if type_match:
            job_data['job_type'] = type_match.group(1).strip()
        
        # ì—­í•  ë° ì±…ì„ ì¶”ì¶œ
        responsibility_match = self.patterns['responsibility'].search(section)
        if responsibility_match:
            responsibilities = responsibility_match.group(1).strip()
            job_data['responsibilities'] = self._parse_bullet_points(responsibilities)
        
        # ìê²©ìš”ê±´ ì¶”ì¶œ
        qualification_match = self.patterns['qualification'].search(section)
        if qualification_match:
            qualifications = qualification_match.group(1).strip()
            job_data['qualifications'] = self._parse_bullet_points(qualifications)
        
        # ìš°ëŒ€ì‚¬í•­ ì¶”ì¶œ
        preferred_match = self.patterns['preferred'].search(section)
        if preferred_match:
            preferred = preferred_match.group(1).strip()
            job_data['preferred'] = self._parse_bullet_points(preferred)
        
        # ì§ë¬´ë¶„ë¥˜ì²´ê³„ ë§¤í•‘
        job_data = self._map_to_category_system(job_data)
        
        return job_data
    
    def _parse_bullet_points(self, text: str) -> List[str]:
        """ë¶ˆë¦¿ í¬ì¸íŠ¸ í…ìŠ¤íŠ¸ íŒŒì‹±"""
        lines = text.strip().split('\n')
        points = []
        
        for line in lines:
            # ë¶ˆë¦¿ ê¸°í˜¸ ì œê±° ë° ì •ë¦¬
            cleaned = re.sub(r'^[-â€¢Â·]\s*', '', line).strip()
            if cleaned:
                points.append(cleaned)
        
        return points
    
    def _map_to_category_system(self, job_data: Dict) -> Dict:
        """OKê¸ˆìœµê·¸ë£¹ ì§ë¬´ë¶„ë¥˜ì²´ê³„ì— ë§¤í•‘"""
        category_name = job_data.get('job_category', '')
        type_name = job_data.get('job_type', '')
        
        # ì§êµ° ë§¤í•‘
        mapped_category = None
        mapped_type = None
        
        for cat_key, cat_value in self.job_categories.items():
            if cat_key in category_name or category_name in cat_key:
                mapped_category = cat_key
                job_data['category_id'] = cat_value['id']
                
                # ì§ì¢… ë§¤í•‘
                for type_key, jobs in cat_value['job_types'].items():
                    if type_key in type_name or type_name in type_key:
                        mapped_type = type_key
                        job_data['type_id'] = f"{cat_value['id']}_{type_key.replace('/', '_')}"
                        break
                break
        
        if not mapped_category:
            self.logger.warning(f"ì§êµ° ë§¤í•‘ ì‹¤íŒ¨: {category_name}")
            job_data['category_id'] = 'undefined'
        
        if not mapped_type:
            self.logger.warning(f"ì§ì¢… ë§¤í•‘ ì‹¤íŒ¨: {type_name}")
            job_data['type_id'] = 'undefined'
        
        job_data['mapped_category'] = mapped_category
        job_data['mapped_type'] = mapped_type
        
        return job_data
    
    def validate_job_data(self, job_data: Dict) -> Tuple[bool, List[str]]:
        """ì§ë¬´ ë°ì´í„° ê²€ì¦"""
        errors = []
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        required_fields = ['job_title', 'responsibilities', 'qualifications']
        for field in required_fields:
            if field not in job_data or not job_data[field]:
                errors.append(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
        
        # ì—­í• /ìê²©ìš”ê±´ ìµœì†Œ ê°œìˆ˜ ê²€ì¦
        if 'responsibilities' in job_data and len(job_data['responsibilities']) < 3:
            errors.append("ì—­í•  ë° ì±…ì„ì´ 3ê°œ ë¯¸ë§Œ")
        
        if 'qualifications' in job_data and len(job_data['qualifications']) < 2:
            errors.append("ìê²©ìš”ê±´ì´ 2ê°œ ë¯¸ë§Œ")
        
        # ì§ë¬´ë¶„ë¥˜ ë§¤í•‘ ê²€ì¦
        if job_data.get('category_id') == 'undefined':
            errors.append("ì§êµ° ë¶„ë¥˜ ë§¤í•‘ ì‹¤íŒ¨")
        
        is_valid = len(errors) == 0
        return is_valid, errors
    
    def parse_all_jobs(self) -> List[Dict]:
        """ì „ì²´ PDF íŒŒì‹± ì‹¤í–‰"""
        self.logger.info("ì§ë¬´ê¸°ìˆ ì„œ íŒŒì‹± ì‹œì‘")
        
        # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
        pages_text = self.extract_text_from_pdf()
        
        # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
        full_text = "\n\n".join([text for _, text in pages_text])
        
        # ì§ë¬´ ì„¹ì…˜ ê°ì§€
        job_sections = self.detect_job_sections(full_text)
        
        # ê° ì„¹ì…˜ íŒŒì‹±
        with tqdm(total=len(job_sections), desc="ì§ë¬´ íŒŒì‹± ì§„í–‰") as pbar:
            for idx, section in enumerate(job_sections):
                # í•´ë‹¹ ì„¹ì…˜ì´ ì†í•œ í˜ì´ì§€ ì°¾ê¸°
                page_num = 1
                for p_num, p_text in pages_text:
                    if section[:100] in p_text:
                        page_num = p_num
                        break
                
                job_data = self.parse_job_section(section, page_num)
                
                if job_data:
                    # ê²€ì¦
                    is_valid, errors = self.validate_job_data(job_data)
                    job_data['is_valid'] = is_valid
                    job_data['validation_errors'] = errors
                    
                    if not is_valid:
                        self.logger.warning(f"ê²€ì¦ ì‹¤íŒ¨ - {job_data.get('job_title', 'Unknown')}: {errors}")
                    
                    self.parsed_jobs.append(job_data)
                
                pbar.update(1)
        
        self.logger.info(f"ì´ {len(self.parsed_jobs)}ê°œ ì§ë¬´ íŒŒì‹± ì™„ë£Œ")
        valid_count = sum(1 for job in self.parsed_jobs if job['is_valid'])
        self.logger.info(f"ìœ íš¨í•œ ì§ë¬´: {valid_count}ê°œ")
        
        return self.parsed_jobs


class JobProfileMigrator:
    """ì§ë¬´ê¸°ìˆ ì„œ ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜"""
    
    def __init__(self, output_dir: str):
        self.output_dir = output_dir
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # Django ì„¤ì •
        os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'ehr_system.settings')
        import django
        django.setup()
    
    def migrate_to_database(self, jobs_data: List[Dict]) -> Dict[str, int]:
        """Django ë°ì´í„°ë² ì´ìŠ¤ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜"""
        from job_profiles.models import JobCategory, JobType, JobRole, JobProfile
        from django.db import transaction
        
        stats = {
            'categories_created': 0,
            'types_created': 0,
            'roles_created': 0,
            'profiles_created': 0,
            'errors': 0
        }
        
        self.logger.info("ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
        
        # ì§êµ°/ì§ì¢… ìƒì„±
        categories_map = {}
        types_map = {}
        
        with transaction.atomic():
            # ì§êµ° ìƒì„±
            for cat_name, cat_data in JobProfilePDFParser(None, None).job_categories.items():
                category, created = JobCategory.objects.get_or_create(
                    name=cat_name,
                    defaults={'is_active': True}
                )
                categories_map[cat_data['id']] = category
                if created:
                    stats['categories_created'] += 1
                
                # ì§ì¢… ìƒì„±
                for type_name in cat_data['job_types']:
                    job_type, created = JobType.objects.get_or_create(
                        category=category,
                        name=type_name,
                        defaults={'is_active': True}
                    )
                    type_id = f"{cat_data['id']}_{type_name.replace('/', '_')}"
                    types_map[type_id] = job_type
                    if created:
                        stats['types_created'] += 1
        
        # ì§ë¬´ í”„ë¡œí•„ ìƒì„±
        with tqdm(total=len(jobs_data), desc="DB ë§ˆì´ê·¸ë ˆì´ì…˜") as pbar:
            for job_data in jobs_data:
                try:
                    if not job_data['is_valid']:
                        self.logger.warning(f"ê²€ì¦ ì‹¤íŒ¨ë¡œ ê±´ë„ˆëœ€: {job_data.get('job_title')}")
                        stats['errors'] += 1
                        pbar.update(1)
                        continue
                    
                    with transaction.atomic():
                        # ì§ë¬´ ì—­í•  ìƒì„±
                        job_type = types_map.get(job_data.get('type_id'))
                        if not job_type:
                            self.logger.error(f"ì§ì¢…ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {job_data.get('type_id')}")
                            stats['errors'] += 1
                            pbar.update(1)
                            continue
                        
                        job_role, created = JobRole.objects.get_or_create(
                            job_type=job_type,
                            name=job_data['job_title'],
                            defaults={'is_active': True}
                        )
                        if created:
                            stats['roles_created'] += 1
                        
                        # ì§ë¬´ í”„ë¡œí•„ ìƒì„±
                        responsibilities_text = '\n'.join(job_data.get('responsibilities', []))
                        qualifications_text = '\n'.join(job_data.get('qualifications', []))
                        preferred_text = '\n'.join(job_data.get('preferred', []))
                        
                        job_profile, created = JobProfile.objects.update_or_create(
                            job_role=job_role,
                            defaults={
                                'role_responsibility': responsibilities_text,
                                'qualification': qualifications_text,
                                'preferred_qualification': preferred_text,
                                'is_active': True
                            }
                        )
                        
                        if created:
                            stats['profiles_created'] += 1
                            self.logger.info(f"ìƒì„±ë¨: {job_data['job_title']}")
                        else:
                            self.logger.info(f"ì—…ë°ì´íŠ¸ë¨: {job_data['job_title']}")
                
                except Exception as e:
                    self.logger.error(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜¤ë¥˜ - {job_data.get('job_title')}: {str(e)}")
                    stats['errors'] += 1
                
                pbar.update(1)
        
        self.logger.info(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: {stats}")
        return stats
    
    def export_to_json(self, jobs_data: List[Dict]) -> str:
        """JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        json_dir = os.path.join(self.output_dir, 'json')
        os.makedirs(json_dir, exist_ok=True)
        
        # ì „ì²´ ë°ì´í„°
        all_jobs_file = os.path.join(json_dir, 'all_job_profiles.json')
        with open(all_jobs_file, 'w', encoding='utf-8') as f:
            json.dump(jobs_data, f, ensure_ascii=False, indent=2)
        
        # ì§êµ°ë³„ ë¶„ë¦¬
        by_category = {}
        for job in jobs_data:
            category = job.get('mapped_category', 'undefined')
            if category not in by_category:
                by_category[category] = []
            by_category[category].append(job)
        
        for category, jobs in by_category.items():
            category_file = os.path.join(json_dir, f'{category.replace("/", "_")}_jobs.json')
            with open(category_file, 'w', encoding='utf-8') as f:
                json.dump(jobs, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"JSON ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {json_dir}")
        return all_jobs_file
    
    def export_to_excel(self, jobs_data: List[Dict]) -> str:
        """Excel íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        excel_dir = os.path.join(self.output_dir, 'excel')
        os.makedirs(excel_dir, exist_ok=True)
        
        excel_file = os.path.join(excel_dir, 'job_profiles_migration.xlsx')
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df_data = []
        for job in jobs_data:
            df_data.append({
                'í˜ì´ì§€': job.get('page_number', ''),
                'ì§êµ°': job.get('mapped_category', ''),
                'ì§ì¢…': job.get('mapped_type', ''),
                'ì§ë¬´ëª…': job.get('job_title', ''),
                'ì—­í•  ë° ì±…ì„': '\n'.join(job.get('responsibilities', [])),
                'ìê²©ìš”ê±´': '\n'.join(job.get('qualifications', [])),
                'ìš°ëŒ€ì‚¬í•­': '\n'.join(job.get('preferred', [])),
                'ê²€ì¦ìƒíƒœ': 'ìœ íš¨' if job.get('is_valid') else 'ê²€ì¦ì‹¤íŒ¨',
                'ê²€ì¦ì˜¤ë¥˜': ', '.join(job.get('validation_errors', []))
            })
        
        df = pd.DataFrame(df_data)
        
        # Excel Writer
        with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
            # ì „ì²´ ë°ì´í„° ì‹œíŠ¸
            df.to_excel(writer, sheet_name='ì „ì²´ì§ë¬´', index=False)
            
            # ì§êµ°ë³„ ì‹œíŠ¸
            for category in df['ì§êµ°'].unique():
                if pd.notna(category):
                    category_df = df[df['ì§êµ°'] == category]
                    sheet_name = category.replace('/', '_')[:31]  # Excel ì‹œíŠ¸ëª… ì œí•œ
                    category_df.to_excel(writer, sheet_name=sheet_name, index=False)
            
            # ê²€ì¦ ì‹¤íŒ¨ ì‹œíŠ¸
            invalid_df = df[df['ê²€ì¦ìƒíƒœ'] == 'ê²€ì¦ì‹¤íŒ¨']
            if not invalid_df.empty:
                invalid_df.to_excel(writer, sheet_name='ê²€ì¦ì‹¤íŒ¨', index=False)
        
        # ìŠ¤íƒ€ì¼ ì ìš©
        wb = openpyxl.load_workbook(excel_file)
        
        for sheet_name in wb.sheetnames:
            ws = wb[sheet_name]
            
            # í—¤ë” ìŠ¤íƒ€ì¼
            header_fill = PatternFill(start_color='366092', end_color='366092', fill_type='solid')
            header_font = Font(color='FFFFFF', bold=True)
            
            for cell in ws[1]:
                cell.fill = header_fill
                cell.font = header_font
                cell.alignment = Alignment(horizontal='center', vertical='center')
            
            # ì—´ ë„ˆë¹„ ìë™ ì¡°ì •
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                
                adjusted_width = min(max_length + 2, 50)
                ws.column_dimensions[column_letter].width = adjusted_width
            
            # í–‰ ë†’ì´ ì¡°ì • (ê¸´ í…ìŠ¤íŠ¸ìš©)
            for row in ws.iter_rows(min_row=2):
                for cell in row:
                    if cell.value and '\n' in str(cell.value):
                        ws.row_dimensions[cell.row].height = 60
                        cell.alignment = Alignment(wrap_text=True, vertical='top')
        
        wb.save(excel_file)
        self.logger.info(f"Excel ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {excel_file}")
        return excel_file
    
    def generate_migration_report(self, jobs_data: List[Dict], stats: Dict) -> str:
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ë¦¬í¬íŠ¸ ìƒì„±"""
        report_file = os.path.join(self.output_dir, 'migration_report.md')
        
        # í†µê³„ ê³„ì‚°
        total_jobs = len(jobs_data)
        valid_jobs = sum(1 for job in jobs_data if job['is_valid'])
        invalid_jobs = total_jobs - valid_jobs
        
        # ì§êµ°ë³„ í†µê³„
        category_stats = {}
        for job in jobs_data:
            category = job.get('mapped_category', 'undefined')
            if category not in category_stats:
                category_stats[category] = {'total': 0, 'valid': 0}
            category_stats[category]['total'] += 1
            if job['is_valid']:
                category_stats[category]['valid'] += 1
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report_content = f"""# OKê¸ˆìœµê·¸ë£¹ ì§ë¬´ê¸°ìˆ ì„œ ë§ˆì´ê·¸ë ˆì´ì…˜ ë¦¬í¬íŠ¸

## ğŸ“Š ì „ì²´ ìš”ì•½
- ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- PDF íŒŒì¼: {os.path.basename(self.output_dir.replace('_migrated', '.pdf'))}
- ì´ ì§ë¬´ ìˆ˜: {total_jobs}ê°œ
- ìœ íš¨ ì§ë¬´: {valid_jobs}ê°œ ({valid_jobs/total_jobs*100:.1f}%)
- ê²€ì¦ ì‹¤íŒ¨: {invalid_jobs}ê°œ

## ğŸ“ˆ ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼
- ì§êµ° ìƒì„±: {stats.get('categories_created', 0)}ê°œ
- ì§ì¢… ìƒì„±: {stats.get('types_created', 0)}ê°œ
- ì§ë¬´ ìƒì„±: {stats.get('roles_created', 0)}ê°œ
- í”„ë¡œí•„ ìƒì„±: {stats.get('profiles_created', 0)}ê°œ
- ì˜¤ë¥˜ ë°œìƒ: {stats.get('errors', 0)}ê±´

## ğŸ“ ì§êµ°ë³„ í˜„í™©
"""
        
        for category, stat in sorted(category_stats.items()):
            report_content += f"""
### {category}
- ì´ ì§ë¬´: {stat['total']}ê°œ
- ìœ íš¨: {stat['valid']}ê°œ ({stat['valid']/stat['total']*100:.1f}%)
"""
        
        # ê²€ì¦ ì‹¤íŒ¨ ìƒì„¸
        if invalid_jobs > 0:
            report_content += "\n## âš ï¸ ê²€ì¦ ì‹¤íŒ¨ ì§ë¬´\n"
            for job in jobs_data:
                if not job['is_valid']:
                    errors = ', '.join(job['validation_errors'])
                    report_content += f"- {job.get('job_title', 'Unknown')}: {errors}\n"
        
        # ì¶œë ¥ íŒŒì¼ ì •ë³´
        report_content += f"""
## ğŸ“¤ ì¶œë ¥ íŒŒì¼
- JSON: {self.output_dir}/json/all_job_profiles.json
- Excel: {self.output_dir}/excel/job_profiles_migration.xlsx
- ë¡œê·¸: {self.output_dir}/logs/

## âœ… ë‹¤ìŒ ë‹¨ê³„
1. ê²€ì¦ ì‹¤íŒ¨ ì§ë¬´ ìˆ˜ë™ í™•ì¸ ë° ìˆ˜ì •
2. ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
3. í”„ë¡œë•ì…˜ í™˜ê²½ ì ìš©
"""
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        self.logger.info(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ë¦¬í¬íŠ¸ ìƒì„±: {report_file}")
        return report_file


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ì„¤ì •
    pdf_path = r"C:/Users/apro/OneDrive/Desktop/ì„¤ëª…íšŒìë£Œ/OK_Job Profile.pdf"
    output_dir = r"C:/Users/apro/OneDrive/Desktop/ì„¤ëª…íšŒìë£Œ/job_profile_migrated"
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    # ë¡œê¹… ì„¤ì •
    logger = setup_logging(output_dir)
    logger.info("="*60)
    logger.info("OKê¸ˆìœµê·¸ë£¹ ì§ë¬´ê¸°ìˆ ì„œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
    logger.info("="*60)
    
    try:
        # 1. PDF íŒŒì‹±
        parser = JobProfilePDFParser(pdf_path, output_dir)
        jobs_data = parser.parse_all_jobs()
        
        if not jobs_data:
            logger.error("íŒŒì‹±ëœ ì§ë¬´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 2. ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜
        migrator = JobProfileMigrator(output_dir)
        
        # Django í™˜ê²½ í™•ì¸
        try:
            stats = migrator.migrate_to_database(jobs_data)
        except Exception as e:
            logger.warning(f"ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {str(e)}")
            logger.info("JSON/Excel ë‚´ë³´ë‚´ê¸°ë§Œ ì§„í–‰í•©ë‹ˆë‹¤.")
            stats = {'errors': len(jobs_data)}
        
        # 3. JSON ë‚´ë³´ë‚´ê¸°
        json_file = migrator.export_to_json(jobs_data)
        
        # 4. Excel ë‚´ë³´ë‚´ê¸°
        excel_file = migrator.export_to_excel(jobs_data)
        
        # 5. ë¦¬í¬íŠ¸ ìƒì„±
        report_file = migrator.generate_migration_report(jobs_data, stats)
        
        # ì™„ë£Œ ë©”ì‹œì§€
        logger.info("="*60)
        logger.info("ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        logger.info(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
        logger.info(f"ë¦¬í¬íŠ¸ í™•ì¸: {report_file}")
        logger.info("="*60)
        
        # ê²°ê³¼ ì¶œë ¥
        print("\nâœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
        print(f"ğŸ“„ JSON: {json_file}")
        print(f"ğŸ“Š Excel: {excel_file}")
        print(f"ğŸ“‹ ë¦¬í¬íŠ¸: {report_file}")
        
    except Exception as e:
        logger.error(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        raise


if __name__ == '__main__':
    # í•„ìš” íŒ¨í‚¤ì§€ í™•ì¸
    required_packages = ['PyMuPDF', 'pandas', 'openpyxl', 'tqdm']
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package.lower().replace('pymupdf', 'fitz'))
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print(f"âš ï¸  í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:")
        print(f"pip install {' '.join(missing_packages)}")
        sys.exit(1)
    
    main()